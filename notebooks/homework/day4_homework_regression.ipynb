{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cisgDApDPUmf"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hR8lFnKoZai"
      },
      "source": [
        "In a regression problem, we aim to predict the output of a continuous value, like a price or a probability. Contrast this with a classification problem, where we aim to select a class from a list of classes (for example, where a picture contains an apple or an orange, recognizing which fruit is in the picture).\n",
        "\n",
        "This notebook uses the classic [Auto MPG Dataset](https://archive.ics.uci.edu/ml/datasets/auto+mpg) and builds a model to predict the fuel efficiency of late-1970s and early 1980s automobiles. To do this, we'll provide the model with a description of many automobiles from that time period. This description includes attributes like: cylinders, displacement, horsepower, and weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yzmMapq-7jSd",
        "outputId": "46291609-1372-45af-a1c7-98b933890795",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-eVT_O687cHu",
        "outputId": "fc03f553-1a95-4993-f145-05da4e9510a0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6kavEvP74ZI"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdvWbZaI8zYt"
      },
      "source": [
        "### Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "EdaUdXrU8PzS",
        "outputId": "42659348-8bec-4745-a440-86e92110935b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "20lpGG7Q8m1y",
        "outputId": "9ff150f2-0372-4842-b44a-761f4af0c3f6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Importing the data with pandas\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvf5HxZDBI2z"
      },
      "source": [
        "### Inspecting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgapr7NiBJSH",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: check the distributions of the features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBpteeP-PhfU"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "stats = dataset.describe().transpose()\n",
        "stats.head(10)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "_i0sA2nMBJUd",
        "outputId": "74a0bcc7-db96-4218-865e-b3dc914f6d9d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Here we plot the distributions of one column w.r.t another one in the extra\n",
        "# diagonal cell and in diagonal cell the univariate distribution of the data\n",
        "# for the variable in that column.\n",
        "# you can check the documentation on seaborn \n",
        "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
        "sns.pairplot(dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4MxsweW8w3h"
      },
      "source": [
        "### Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH35jEwZ9CNT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: check if there is Nan values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPjPZthZQPVz"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "dataset.isna().sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX2Ny62B-ne1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: since it's only a few rows we can just drop the Nan values\n",
        "# (EXTRA: what else could we do?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4_rfu66Qcvn"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "dataset = dataset.dropna()\n",
        "print(dataset.shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV4M7c5H-yO_"
      },
      "source": [
        "From the documentation here are the columns:\n",
        "1. mpg: continuous\n",
        "2. cylinders: multi-valued discrete\n",
        "3. displacement: continuous\n",
        "4. horsepower: continuous\n",
        "5. weight: continuous\n",
        "6. acceleration: continuous\n",
        "7. model year: multi-valued discrete\n",
        "8. origin: multi-valued discrete\n",
        "9. car name: string (unique for each instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppdTxbqW_Fl7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: convert discrete columns to one-hot if relevant\n",
        "# (i.e. if there is a restricted number of categories and there is no value added with their numeric values, like ranking or others )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXnOl0NXQi5H"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Check the set of possible numerical values and if it's relevant to order them\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "To convert to one-hot vartiable there is a pandas method very helpful. Check it <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\">here !</a>\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "print(dataset['Cylinders'].unique())\n",
        "print(dataset['Model Year'].unique())\n",
        "print(dataset['Origin'].unique())\n",
        "\n",
        "# cylinders and Model Years can actually be compared with their numeric values so we keep it\n",
        "dataset['Origin'] = dataset['Origin'].map(lambda x: {1: 'USA', 2: 'Europe', 3: 'Japan'}.get(x))\n",
        "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
        "dataset.tail()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNsCsHhJAeuU"
      },
      "source": [
        "### Splitting the dataset in train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x282-RS2AhI-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: split the dataset with 80% in test and 20% in train\n",
        "# using https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html \n",
        "# (use the random_state=0 we all use the same)\n",
        "# Extract then the labels and the feature separately\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YThioyBCSH2h"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "# .pop() removes the column from the dataframe and return it\n",
        "train_labels = train_dataset.pop('MPG').values\n",
        "test_labels = test_dataset.pop('MPG').values\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxxGcDJBA8r-"
      },
      "source": [
        "### Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOqOHIIPBtcL",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: build a function to normalize the dataset (ie 0-mean and 1-std) fropm the training statistics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL3GjepCSUA-"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "You need to store the training mean/std so you can apply the same normalization to the test-data\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "train_stats = train_dataset.describe().transpose()\n",
        "\n",
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset).values\n",
        "normed_test_data = norm(test_dataset).values\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5_6_xA8CSR-"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DznqQWllGzK4"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYd1EnAnCqt9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: build a Keras model with 2 hidden fully connected layers and one output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVMTPaEDS5Lr"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Choose wisely about the size of your layers\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Don't forget to compile your models and think about which regression metrics you care about\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Wrapp the model building in a function so later on you just need to call this function\n",
        "</details>\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model\n",
        "  \n",
        "model = build_model()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "UGFZkhWzDal7",
        "outputId": "40c4772e-dc10-4484-b5aa-8024402b6df4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Inspect the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3jBO0cqDirg"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1ZHNTnMDs0S",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: train your models for 1000 epochs, don't forget to add your validation data in\n",
        "# the training so you record the evolution of its loss as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGNN8extTe5v"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=1000, validation_split = 0.2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8_Obm_AjEVIt",
        "outputId": "9b0a7968-2c3d-40ce-ae2f-39b2a2a50d1a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame(history.history).reset_index().rename(columns={'index': 'epochs'})\n",
        "history_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYH_eef6Ezph",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: plot the evolution of the metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxI1H5M0UAY7"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
        "\n",
        "for i, metric in enumerate(['loss', 'mae', 'mse']):\n",
        "  ax = axes[i]\n",
        "  history_df.plot('epochs', f'{metric}', color='g', label='train', ax=ax)\n",
        "  history_df.plot('epochs', f'val_{metric}', color='r', label='test', ax=ax)\n",
        "  ax.set_ylabel(metric)\n",
        "  ax.set_ylim([0, 20])\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keXoew7oHOBY"
      },
      "source": [
        "Make some observations from your plots:\n",
        "- Is the metric evolving similarly in your train and in your test set?\n",
        "- Are you observing a flaw in your model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4uBVkR3IiUS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: evaluate the model on your test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBF5hDCuUf8J"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        " loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO2AIgEMGAqf"
      },
      "source": [
        "### Early-stopping\n",
        "\n",
        "To prevent from overfitting you can stop the training once the performances of your model on heldout data (= data not seen at training) starts to decrease. Then you record the number of epoch at which you should stop.\n",
        "\n",
        "Keras implements this as a callbacks, it's a method which is called during training and can impact the training loops.\n",
        "\n",
        "Check [here](https://keras.io/callbacks/#earlystopping) the documentation on how to use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLvr_dPBG3V2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Add early stopping in your training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQaN-7IiUsYn"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=1000,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlfVricMIDzE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: plots the evolution of the metrics during training with the history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh7BiQi0UtYx"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
        "\n",
        "for i, metric in enumerate(['loss', 'mae', 'mse']):\n",
        "  ax = axes[i]\n",
        "  history_df.plot('epochs', f'{metric}', color='g', label='train', ax=ax)\n",
        "  history_df.plot('epochs', f'val_{metric}', color='r', label='test', ax=ax)\n",
        "  ax.set_ylabel(metric)\n",
        "  ax.set_ylim([0, 20])\n",
        "plt.show()\n",
        "\n",
        "history_df = pd.DataFrame(history.history).reset_index().rename(columns={'index': 'epochs'})\n",
        "history_df.tail()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBhcEpN2ILjE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate the results on your test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fk5mWBtUuZR"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQPmFts0Wkyr"
      },
      "source": [
        "You've found out when to stop training in order not to overfit to your train data, but you fitted your model only on 80% of the training data. Don't forget that the data is your most important source of information so you should use the maximum of it.\n",
        "\n",
        "How to do this? You can get the optimized number of epoch to fit your model and then use it when fitting your model on the whole train set !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weNR6y5XWmn2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: extract the number of epoch at which the early stopping triggered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwLhtoNlWmqW"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "This number is stored in the attribute `.stopped_epoch` of your early_stop callback\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>Hints\n",
        "</summary>\n",
        "Retrieve from it the patience since you want only the number of steps needed to reach the best performances on your validation set\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "num_epoch_optimized = es.stopped_epoch - patience\n",
        "print(num_epoch_optimized)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGwQW0LxXSX4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Fit your model on all your train data this time with the optimized\n",
        "# number of epochs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv6ww6zdXSa8"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "model = build_model()\n",
        " \n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
        " \n",
        "history = model.fit(normed_train_data, train_labels, epochs=num_epoch_optimized, verbose=2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8IgabPrXSdV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate the results on your test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-pVerbkXSf1"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "# Evaluate the results on your test data\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDKB1USbI1Zw"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ukxh1d2TI3RE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# TODO: predict the values of your test data and plot the true values VS the predicted values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqfCfvNsUvUD"
      },
      "source": [
        "<details>\n",
        "<summary markdown='span'>View solution\n",
        "</summary>\n",
        "\n",
        "```python\n",
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "plt.plot(lims, lims)\n",
        "\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yie42u9iJXOh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "day4_homework_regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
