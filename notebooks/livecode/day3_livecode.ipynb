{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "loans_df =  pd.read_csv('../../data/loans_day3.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show first 5 lines\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is not the dataset that we had in day 1. We have prepared this dataset a bit so that we can better use it in our ML models. This act of treating the data is called `preprocessing`. It was a bit much to fit in one lecture but don't worry.. we've prepared a homework concerning these topics for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsample for live code\n",
    "loans_df = loans_df.sample(50000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember with regression tasks we want to predict a continous variable. In our example we're going to try to predict `loan_amnt` with our other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example\n",
    "\n",
    "Let's code through a simple example and see how we can infere our intercept and slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 50 observations\n",
    "loans_df_small = loans_df.sample(50)\n",
    "\n",
    "#split into X and y\n",
    "X_small = loans_df_small[['annual_inc']]\n",
    "y_small = loans_df_small['loan_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot our observations as a scatterplot\n",
    "sns.scatterplot(X_small['annual_inc'], y_small);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "lin_reg.fit(X_small, y_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model we can use the `.intercept_` and `.coef_` attributes to get our intercept and slope. Then we can plot our line-of-best-fit on our scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = lin_reg.intercept_\n",
    "slope = lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(X_small['annual_inc'], y_small)\n",
    "plt.plot(X_small['annual_inc'], intercept+slope*X_small, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data so we can see how well our model generalises. Remember with `generalize` we mean the ability of a model to handle unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define x & y because we don't wanna scale our target\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = loans_df.drop(columns=['loan_amnt'])\n",
    "\n",
    "y = loans_df.loan_amnt\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the most basic models but still one of the go-to models in reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, meaning our model knows the ideal intercept and slopes for all features, we can score it using the metrics we saw during the lecture.\n",
    "\n",
    "We will first have to use the `.predict()` to get our predictions for `X` using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error\n",
    "\n",
    "#get our predictions\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "#score our model\n",
    "lin_mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "lin_mae = mean_absolute_error(y_test, y_pred)\n",
    "lin_max_er = max_error(y_test, y_pred)\n",
    "\n",
    "# print(f\"The MSE for our model is {lin_mse}\")\n",
    "# print(f\"The MAE for our model is {lin_mae}\")\n",
    "# print(f\"The Max error for our model is {lin_max_er}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same process using a `decision tree regressor`. We can then use the metrics to see which model performs better in which case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate the model\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "# Train the model on the Training data\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get our predictions\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "#score our model\n",
    "tree_mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "tree_mae = mean_absolute_error(y_test, y_pred)\n",
    "tree_max_er = max_error(y_test, y_pred)\n",
    "\n",
    "# print(f\"The MSE for our model is {tree_mse}\")\n",
    "# print(f\"The MAE for our model is {tree_mae}\")\n",
    "# print(f\"The Max error for our model is {tree_max_er}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE Linear Regression: {round(lin_mse,2)}, RMSE Decision tree {round(tree_mse,2)}\")\n",
    "print(f\"MAE Linear Regression: {round(lin_mae,2)}, MAE Decision tree {round(tree_mae,2)}\")\n",
    "print(f\"Max error Linear Regression: {round(lin_max_er,2)}, Max error Decision tree {round(tree_max_er,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our decision tree model performs better across the board!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With classification we're trying to predict a specific class represented by binary values. Let's use an `SVM` and `Decision Tree Classifier` to try to predict `loan_status`. Afterwards we will use the different metrics we learned and see how our models compare to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define x & y because we don't wanna scale our target\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = loans_df.drop(columns=['loan_status'])\n",
    "\n",
    "y = loans_df.loan_status\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the lecture we can use a `SVM` for classification tasks. Let's fit, train and score a model on our dateset.\n",
    "\n",
    "We'll use an `RBF kernel` in our SVM model. This is quite high level for now so what you should understand here is that it allows our model to use higher dimensions for the seperation of the data. Using a `linear kernel` here would be difficult since our data will not be linearly seperable.\n",
    "\n",
    "Please take note that it can take some time to fit :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate the model => we use an rbf kernel to work in higher dimension as this dataset will not be linearly seperable\n",
    "svm = SVC(kernel='rbf' , class_weight={0:4,1:1})\n",
    "\n",
    "# Train the model on the Training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the Test data\n",
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a minute to think about our score here. \n",
    "\n",
    "The `.score()` method gives back our `accuracy-score`. So our 62% accuracy is the amount of observations our model was right about. Seems relatively good right?\n",
    "\n",
    "But let's have a look again at the distribution of our `loan_status` status variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check value counts\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of most dominant class\n",
    "y.sum() / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by calculating the percentage `fully paid` on the total y column, we can see that this class consists of about 80% of the total amount of observations. \n",
    "\n",
    "This means that if we would have just guessed this category everytime we would have been right about 80% of the time, which is better than our model.\n",
    "\n",
    "Let's look into our other metrics to see how our model performs there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate y_pred\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "#calculate scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy, recall, precision, f1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some increases in performance here but still not great. Let's try another model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#instantiate model\n",
    "tree_reg = DecisionTreeClassifier()\n",
    "\n",
    "#fit model to our training data\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "#we can use the built-in method .score() to get our accuracy score\n",
    "tree_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "# calculate y_pred\n",
    "y_pred = tree_reg.predict(X_test)\n",
    "\n",
    "#calculate scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy, recall, precision, f1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into our other metrics we see that the model performs a lot better than the SVM one. Still not the score we are looking for though. Let's see tomorrow if we can improve with DL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dforb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e9ae77a68d479a28967a79b3dd1a040f581e32c13de9b5e9a3a6cf002e7768e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
